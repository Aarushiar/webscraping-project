{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ffe1159-4bc3-4d8f-b1a0-b0623b466dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "BASE_URL = \"https://www.fiverr.com/categories/programming-tech/ai-services?source=category_tree\"  # Specific category URL\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 11.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Referer\": \"https://www.fiverr.com/\",  # Add a referer\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Cache-Control\": \"max-age=0\"\n",
    "}\n",
    "OUTPUT_FORMAT = os.getenv(\"OUTPUT_FORMAT\", \"json\")  # Default output format is JSON\n",
    "MIN_DELAY = int(os.getenv(\"MIN_DELAY\", 3))  # Minimum delay in seconds\n",
    "MAX_DELAY = int(os.getenv(\"MAX_DELAY\", 7))  # Maximum delay in seconds\n",
    "\n",
    "# --- Logging Setup ---\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "file_handler = logging.FileHandler(\"fiverr_scraper_simplified.log\")  # Updated log file name\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "def log_error(message):\n",
    "    logger.error(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "827d8e2e-7ac7-44b4-bc5f-defe5e04fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "    def __init__(self, headers, min_delay, max_delay):\n",
    "        self.headers = headers\n",
    "        self.min_delay = min_delay\n",
    "        self.max_delay = max_delay\n",
    "\n",
    "    def fetch_page(self, url):\n",
    "        \"\"\"Fetches a webpage with error handling.\"\"\"\n",
    "        try:\n",
    "            time.sleep(random.uniform(self.min_delay, self.max_delay))\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            return response.content\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            log_error(f\"Error fetching {url}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def parse_project_listings(self, html_content):\n",
    "        \"\"\"Parses project listings from the HTML content.\"\"\"\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        project_listings = []\n",
    "\n",
    "        # Find project listing elements on Fiverr (adjust selectors as needed)\n",
    "        gigs = soup.find_all(\"li\", class_=\"gig-card-layout\")\n",
    "\n",
    "        for gig in gigs:\n",
    "            try:\n",
    "                title = gig.find(\"h3\", class_=\"text-display-7 font-semibold\").text.strip()\n",
    "                description = gig.find(\"div\", class_=\"expanded-gig-description\").text.strip()\n",
    "\n",
    "                # Extract the project link from the <a> tag\n",
    "                project_link = BASE_URL + gig.find(\"a\", class_=\"stretched-link-overlay\")[\"href\"]\n",
    "\n",
    "                # Fetch and parse the project details page\n",
    "                project_details_html = self.fetch_page(project_link)\n",
    "\n",
    "                if project_details_html:\n",
    "                    project_details_soup = BeautifulSoup(project_details_html, \"html.parser\")\n",
    "                    \n",
    "                    # Budget: Look for a package table or starting price\n",
    "                    budget_element = project_details_soup.find(\"span\", class_=\"price-item\")\n",
    "                    budget = budget_element.text.strip() if budget_element else \"N/A\"\n",
    "\n",
    "                    # Skills: Look for tags or keywords\n",
    "                    skills_elements = project_details_soup.find_all(\"span\", class_=\"tag-name\")\n",
    "                    skills = [skill.text.strip() for skill in skills_elements]\n",
    "\n",
    "                    # Posted Date: Might be in the seller's profile\n",
    "                    date_posted = \"N/A\"  # Can try to extract from seller profile if available\n",
    "\n",
    "                    # Client Country: Usually associated with the seller\n",
    "                    client_country_element = project_details_soup.find(\"div\", class_=\"seller-location\")\n",
    "                    client_country = client_country_element.text.strip() if client_country_element else \"N/A\"\n",
    "\n",
    "                else:\n",
    "                    budget = \"N/A\"\n",
    "                    skills = []\n",
    "                    date_posted = \"N/A\"\n",
    "                    client_country = \"N/A\"\n",
    "\n",
    "                project_listings.append(\n",
    "                    {\n",
    "                        \"title\": title,\n",
    "                        \"description\": description,\n",
    "                        \"budget\": budget,\n",
    "                        \"skills\": skills,\n",
    "                        \"date_posted\": date_posted,\n",
    "                        \"client_country\": client_country\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                log_error(f\"Error parsing project: {e}\")\n",
    "\n",
    "        return project_listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "604cf5c2-f798-4e1a-992c-9ce4a1c24553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self, output_format=\"json\", output_filename=\"fiverr_ai_projects\"):\n",
    "        self.output_format = output_format\n",
    "        self.output_filename = output_filename\n",
    "\n",
    "    def save_data(self, data):\n",
    "        \"\"\"Saves the scraped data to a file (JSON or CSV).\"\"\"\n",
    "        try:\n",
    "            if self.output_format == \"json\":\n",
    "                with open(f\"{self.output_filename}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "                logger.info(f\"Data successfully saved to {self.output_filename}.json\")\n",
    "            elif self.output_format == \"csv\":\n",
    "                with open(f\"{self.output_filename}.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                    # Provide an empty list [] as the default for fieldnames if data is empty\n",
    "                    writer = csv.DictWriter(f, fieldnames=data[0].keys() if data else [])\n",
    "                    writer.writeheader()\n",
    "                    writer.writerows(data)\n",
    "                logger.info(f\"Data successfully saved to {self.output_filename}.csv\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported output format: {self.output_format}\")\n",
    "        except (IOError, TypeError, ValueError) as e:\n",
    "            log_error(f\"Error saving data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccd48213-c374-481c-aa91-fd31dc5010d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self, output_format=\"json\", output_filename=\"fiverr_ai_projects\"):\n",
    "        self.output_format = output_format\n",
    "        self.output_filename = output_filename\n",
    "\n",
    "    def save_data(self, data):\n",
    "        \"\"\"Saves the scraped data to a file (JSON or CSV).\"\"\"\n",
    "        try:\n",
    "            if self.output_format == \"json\":\n",
    "                with open(f\"{self.output_filename}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "                logger.info(f\"Data successfully saved to {self.output_filename}.json\")\n",
    "            elif self.output_format == \"csv\":\n",
    "                with open(f\"{self.output_filename}.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                    writer = csv.DictWriter(f, fieldnames=data[0].keys() if data else [])\n",
    "                    writer.writeheader()\n",
    "                    writer.writerows(data)\n",
    "                logger.info(f\"Data successfully saved to {self.output_filename}.csv\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported output format: {self.output_format}\")\n",
    "        except (IOError, TypeError, ValueError) as e:\n",
    "            log_error(f\"Error saving data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9212e8c3-1f1f-4ee5-9d7a-fed45e9ef38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the scraper.\"\"\"\n",
    "    logger.info(\"Starting the simplified Fiverr AI project scraper...\")\n",
    "\n",
    "    scraper = Scraper(HEADERS, MIN_DELAY, MAX_DELAY)\n",
    "    data_handler = DataHandler(output_format=OUTPUT_FORMAT)\n",
    "\n",
    "    html_content = scraper.fetch_page(BASE_URL)\n",
    "\n",
    "    if html_content:\n",
    "        projects = scraper.parse_project_listings(html_content)\n",
    "        if projects:\n",
    "            data_handler.save_data(projects)\n",
    "        else:\n",
    "            logger.info(\"No projects found.\")\n",
    "    else:\n",
    "        logger.error(\"Failed to fetch the category page.\")\n",
    "\n",
    "    logger.info(\"Scraping finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "206aecb3-6faf-42d0-9cb8-0cf7751e6595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 23:41:26,550 - __main__ - INFO - Starting the simplified Fiverr AI project scraper...\n",
      "2025-01-09 23:41:26,550 - __main__ - INFO - Starting the simplified Fiverr AI project scraper...\n",
      "2025-01-09 23:41:26,550 - __main__ - INFO - Starting the simplified Fiverr AI project scraper...\n",
      "2025-01-09 23:41:31,696 - __main__ - ERROR - Error fetching https://www.fiverr.com/categories/programming-tech/ai-services?source=category_tree: 403 Client Error: Forbidden for url: https://www.fiverr.com/categories/programming-tech/ai-services?source=category_tree\n",
      "2025-01-09 23:41:31,696 - __main__ - ERROR - Error fetching https://www.fiverr.com/categories/programming-tech/ai-services?source=category_tree: 403 Client Error: Forbidden for url: https://www.fiverr.com/categories/programming-tech/ai-services?source=category_tree\n",
      "2025-01-09 23:41:31,696 - __main__ - ERROR - Error fetching https://www.fiverr.com/categories/programming-tech/ai-services?source=category_tree: 403 Client Error: Forbidden for url: https://www.fiverr.com/categories/programming-tech/ai-services?source=category_tree\n",
      "2025-01-09 23:41:31,703 - __main__ - ERROR - Failed to fetch the category page.\n",
      "2025-01-09 23:41:31,703 - __main__ - ERROR - Failed to fetch the category page.\n",
      "2025-01-09 23:41:31,703 - __main__ - ERROR - Failed to fetch the category page.\n",
      "2025-01-09 23:41:31,713 - __main__ - INFO - Scraping finished.\n",
      "2025-01-09 23:41:31,713 - __main__ - INFO - Scraping finished.\n",
      "2025-01-09 23:41:31,713 - __main__ - INFO - Scraping finished.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1c8cb-9ae2-4f25-b8ad-dcad9d1c7d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
